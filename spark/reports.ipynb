{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc598dbe-3d04-40d4-9a16-08026cc0b379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in /opt/conda/lib/python3.10/site-packages (8.0.31)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.11.0 in /opt/conda/lib/python3.10/site-packages (from mysql-connector-python) (3.20.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mysql-connector-python\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40fcb868-0ac0-4316-9a5a-c83e3a56045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import mysql.connector\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9feaac4a-d5b0-4812-a9bf-ae422fe937f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('reports') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec58aa62-fb8c-4f76-80fe-8e3726965ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# login information\n",
    "host = 'warehouse' # find in docker-compose.yml, line 5\n",
    "port = '3306' # find in docker-compose.yml, line 13\n",
    "user = 'root' # located in .env file, but hard coded here\n",
    "password = 'root' # located in .env file, but hard coded here\n",
    "database = 'WAREHOUSE' # located in .env file, but hard coded here\n",
    "\n",
    "# establish connection to mysql database\n",
    "connection = mysql.connector.connect(user=user, password=password, host=host, port=port, database=database, auth_plugin='mysql_native_password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2c2ebe2-9e80-4f13-bef8-81421dd0d1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- First Name: string (nullable = true)\n",
      " |-- Middle Inital: string (nullable = true)\n",
      " |-- Last Name: string (nullable = true)\n",
      " |-- SSN: string (nullable = true)\n",
      " |-- Birthdate: date (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Salary: decimal(38,18) (nullable = true)\n",
      " |-- Supervisor SSN: string (nullable = true)\n",
      " |-- Department Number: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get all data in `EMPLOYEE` table\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# get data\n",
    "cursor.execute('SELECT * FROM EMPLOYEE')\n",
    "data = cursor.fetchall()\n",
    "\n",
    "# pandas df\n",
    "pandas_df = pd.DataFrame(data, columns=['First Name', 'Middle Inital', 'Last Name', 'SSN', 'Birthdate', 'Address', 'Sex', 'Salary', 'Supervisor SSN', 'Department Number'])\n",
    "\n",
    "# turn pandas df to spark df\n",
    "spark_df = spark.createDataFrame(pandas_df)\n",
    "\n",
    "# show schema of data\n",
    "spark_df.printSchema()\n",
    "\n",
    "# convert spark df to a table so spark sql can be used\n",
    "spark_df.createTempView('EMPLOYEE')\n",
    "\n",
    "# query all data from spark df\n",
    "result = spark.sql(\"\"\"SELECT * FROM EMPLOYEE\"\"\")\n",
    "\n",
    "# query returns all data in 'EMPLOYEE' table'\n",
    "# spark will save it as many parquet files\n",
    "# use coalesce(n) to reduce the number of partitions to n\n",
    "result.coalesce(1).write.parquet('./work/data/employee_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "767a1deb-f3ad-4600-9806-c5d5d72e4658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Department Name: string (nullable = true)\n",
      " |-- Department Number: long (nullable = true)\n",
      " |-- Manager SSN: string (nullable = true)\n",
      " |-- Manager Start Date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get all data in `DEPARTMENT` table\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# get data\n",
    "cursor.execute('SELECT * FROM DEPARTMENT')\n",
    "data = cursor.fetchall()\n",
    "\n",
    "# pandas df\n",
    "pandas_df = pd.DataFrame(data, columns=['Department Name', 'Department Number', 'Manager SSN', 'Manager Start Date'])\n",
    "\n",
    "# turn pandas df to spark df\n",
    "spark_df = spark.createDataFrame(pandas_df)\n",
    "\n",
    "# show schema of data\n",
    "spark_df.printSchema()\n",
    "\n",
    "# convert spark df to a table so spark sql can be used\n",
    "spark_df.createTempView('DEPARTMENT')\n",
    "\n",
    "# query all data from spark df\n",
    "result = spark.sql(\"\"\"SELECT * FROM DEPARTMENT\"\"\")\n",
    "\n",
    "# query returns all data in 'DEPARTMENT' table'\n",
    "# spark will save it as many parquet files\n",
    "# use coalesce(n) to reduce the number of partitions to n\n",
    "result.coalesce(1).write.parquet('./work/data/department_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75222a12-e770-4647-88e0-15531b15db8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Department Number: long (nullable = true)\n",
      " |-- Department Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get all data in `DEPT_LOCATIONS` table\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# get data\n",
    "cursor.execute('SELECT * FROM DEPT_LOCATIONS')\n",
    "data = cursor.fetchall()\n",
    "\n",
    "# pandas df\n",
    "pandas_df = pd.DataFrame(data, columns=['Department Number', 'Department Location'])\n",
    "\n",
    "# turn pandas df to spark df\n",
    "spark_df = spark.createDataFrame(pandas_df)\n",
    "\n",
    "# show schema of data\n",
    "spark_df.printSchema()\n",
    "\n",
    "# convert spark df to a table so spark sql can be used\n",
    "spark_df.createTempView('DEPT_LOCATIONS')\n",
    "\n",
    "# query all data from spark df\n",
    "result = spark.sql(\"\"\"SELECT * FROM DEPT_LOCATIONS\"\"\")\n",
    "\n",
    "# query returns all data in 'DEPT_LOCATIONS' table'\n",
    "# spark will save it as many parquet files\n",
    "# use coalesce(n) to reduce the number of partitions to n\n",
    "result.coalesce(1).write.parquet('./work/data/department_locations_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd354ad7-5bd1-4be9-8507-960ce7ec416a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Project Name: string (nullable = true)\n",
      " |-- Project Number: long (nullable = true)\n",
      " |-- Project Location: string (nullable = true)\n",
      " |-- Department Number: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get all data in `PROJECT` table\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# get data\n",
    "cursor.execute('SELECT * FROM PROJECT')\n",
    "data = cursor.fetchall()\n",
    "\n",
    "# pandas df\n",
    "pandas_df = pd.DataFrame(data, columns=['Project Name', 'Project Number', 'Project Location', 'Department Number'])\n",
    "\n",
    "# turn pandas df to spark df\n",
    "spark_df = spark.createDataFrame(pandas_df)\n",
    "\n",
    "# show schema of data\n",
    "spark_df.printSchema()\n",
    "\n",
    "# convert spark df to a table so spark sql can be used\n",
    "spark_df.createTempView('PROJECT')\n",
    "\n",
    "# query all data from spark df\n",
    "result = spark.sql(\"\"\"SELECT * FROM PROJECT\"\"\")\n",
    "\n",
    "# query returns all data in 'PROJECT' table'\n",
    "# spark will save it as many parquet files\n",
    "# use coalesce(n) to reduce the number of partitions to n\n",
    "result.coalesce(1).write.parquet('./work/data/project_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8613b211-1d43-4a26-b45e-d7a56f1e5c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Employee SSN: string (nullable = true)\n",
      " |-- Project Number: long (nullable = true)\n",
      " |-- Hours: decimal(38,18) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get all data in `WORKS_ON` table\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# get data\n",
    "cursor.execute('SELECT * FROM WORKS_ON')\n",
    "data = cursor.fetchall()\n",
    "\n",
    "# pandas df\n",
    "pandas_df = pd.DataFrame(data, columns=['Employee SSN', 'Project Number', 'Hours'])\n",
    "\n",
    "# turn pandas df to spark df\n",
    "spark_df = spark.createDataFrame(pandas_df)\n",
    "\n",
    "# show schema of data\n",
    "spark_df.printSchema()\n",
    "\n",
    "# convert spark df to a table so spark sql can be used\n",
    "spark_df.createTempView('WORKS_ON')\n",
    "\n",
    "# query all data from spark df\n",
    "result = spark.sql(\"\"\"SELECT * FROM WORKS_ON\"\"\")\n",
    "\n",
    "# query returns all data in 'WORKS_ON' table'\n",
    "# spark will save it as many parquet files\n",
    "# use coalesce(n) to reduce the number of partitions to n\n",
    "result.coalesce(1).write.parquet('./work/data/works_on_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f1f1a0f-529d-433d-9cdc-b149c6ac1cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Employee SSN: string (nullable = true)\n",
      " |-- Dependent Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Birthdate: date (nullable = true)\n",
      " |-- Relationship: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get all data in `DEPENDENT` table\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# get data\n",
    "cursor.execute('SELECT * FROM DEPENDENT')\n",
    "data = cursor.fetchall()\n",
    "\n",
    "# pandas df\n",
    "pandas_df = pd.DataFrame(data, columns=['Employee SSN', 'Dependent Name', 'Sex', 'Birthdate', 'Relationship'])\n",
    "\n",
    "# turn pandas df to spark df\n",
    "spark_df = spark.createDataFrame(pandas_df)\n",
    "\n",
    "# show schema of data\n",
    "spark_df.printSchema()\n",
    "\n",
    "# convert spark df to a table so spark sql can be used\n",
    "spark_df.createTempView('DEPENDENT')\n",
    "\n",
    "# query all data from spark df\n",
    "result = spark.sql(\"\"\"SELECT * FROM DEPENDENT\"\"\")\n",
    "\n",
    "# query returns all data in 'DEPENDENT' table'\n",
    "# spark will save it as many parquet files\n",
    "# use coalesce(n) to reduce the number of partitions to n\n",
    "result.coalesce(1).write.parquet('./work/data/dependent_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78a7eb1-c0b1-463a-80ed-9f07d158da44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
